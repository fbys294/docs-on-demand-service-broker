---
title: Getting Started&#58; ODB on a Local Development Environment
owner: London Services Enablement
---

This guide describes how to create and manage an on-demand service using PCF Dev and BOSH lite, which are tools that allow you run BOSH and Pivotal Cloud Foundry on a local development machine. This tutorial bases its example service on [Kafka open source messaging](http://kafka.apache.org) and uses the following sample code directories:

* [Kafka example service](https://github.com/pivotal-cf-experimental/kafka-example-service-release)
* [Kafka example service adapter](https://github.com/pivotal-cf-experimental/kafka-example-service-adapter)
* [Kafka example app](https://github.com/pivotal-cf-experimental/kafka-example-app)

## <a id="prereq"></a>Prerequisites

Before setting up and using ODB on your local development environment, install and configure the following components:

- [BOSH Lite](https://github.com/cloudfoundry/bosh-lite#install-bosh-lite) - *min version <%= vars.odb_bosh_lite_version %>*

 <p class="note"><strong>Note</strong>: For PCF Dev to route requests to the deployments on BOSH Lite ensure you run the script `bin/add-route` in the BOSH Lite repository. You may need to run this again if your networking is reset (e.g. reboot, or connecting to a different network).</p>

- [PCF Dev](https://docs.pivotal.io/pcf-dev/#installing) - *[<%= vars.odb_pcfdev_version %>](https://network.pivotal.io/products/pcfdev#/releases/<%= vars.odb_pcfdev_version_pivnet %>)*

- Once PCF Dev has finished installing, you should see some output like this...

  ```
      _______  _______  _______    ______   _______  __   __
    |       ||       ||       |  |      | |       ||  | |  |
    |    _  ||       ||    ___|  |  _    ||    ___||  |_|  |
    |   |_| ||       ||   |___   | | |   ||   |___ |       |
    |    ___||      _||    ___|  | |_|   ||    ___||       |
    |   |    |     |_ |   |      |       ||   |___  |     |
    |___|    |_______||___|      |______| |_______|  |___|
    is now running.
    To begin using PCF Dev, please run:
       cf login -a https://api.local.pcfdev.io --skip-ssl-validation
    Apps Manager URL: https://local.pcfdev.io
    Admin user => Email: admin / Password: admin
  ```

  Make a note of the PCF Dev domain, you will need this later on. The default is `local.pcfdev.io`.

## <a id="about-cli"></a>About the BOSH CLI
The BOSH CLI is available in two major versions, v1 and v2. Pivotal recommends that you use the BOSH CLI v2 when possible.

This topic provides examples of using each version of the BOSH CLI. Your PCF installation may affect which version of the BOSH CLI you can use. Consult the table below to determine which version of the CLI is supported for your installation.

<table class="nice">
    <th>PCF Version</th>
    <th>BOSH CLI Version</th>
    <tr>
        <td>1.10</td>
        <td>CLI v1</td>
    </tr>
    <tr>
        <td>1.11</td>
        <td>CLI v1 or CLI v2 (Pivotal recommends CLI v2)</td>
    </tr>
    <tr>
        <td>1.12 and later</td>
        <td>CLI v2</td>
    </tr>
</table>

## <a id="set_up_bosh"></a>Step 1: Set Up BOSH Lite

1. Target your BOSH Lite installation:
   <pre class="terminal">
    $ bosh target
    Current target is https<span>:</span>//192.168.50.4:25555 (Bosh Lite Director)
   </pre>

1. Upload the [BOSH Lite stemcell](http://bosh.cloudfoundry.org/stemcells/bosh-warden-boshlite-ubuntu-trusty-go_agent):
   <pre class="terminal">
    $ bosh upload stemcell https<span>:</span>//bosh.io/d/stemcells/bosh-warden-boshlite-ubuntu-trusty-go_agent?v=<%= vars.odb_warden_stemcell_version %>
   </pre>

## <a id="set_up_kafka_sr"></a> Step 2: Set Up the Kafka Example Service

1. Clone the [Kafka example service](https://github.com/pivotal-cf-experimental/kafka-example-service-release) into your workspace:
   <pre class="terminal">
    $ git clone https<span>:</span>//github.com/pivotal-cf-experimental/kafka-example-service-release.git
   </pre>

1. In the `kafka-example-service-release` directory, create and upload the kafka example service:
   <pre class="terminal">
    $ cd kafka-example-service-release
    $ bosh create release --name kafka-example-service
   </pre>

1. Upload the service to the BOSH director:
  <pre class="terminal">
    $ bosh upload release
  </pre>

## <a id="set_up_kafka_sa"></a> Step 3: Set Up the Kafka Example Service Adapter

1. Clone the [Kafka example service adapter](https://github.com/pivotal-cf-experimental/kafka-example-service-adapter-release) and run `git submodule update --init` to bring in the adapter's dependencies
   <pre class="terminal">
    $ git clone https<span>:</span>//github.com/pivotal-cf-experimental/kafka-example-service-adapter-release.git
   </pre>

1. Update the service adapter dependencies:
  <pre class="terminal">
    $ cd kafka-example-service-adapter-release
    $ git submodule update --init --recursive
  </pre>

1. Create the example service adapter:
  <pre class="terminal">
    $ bosh create release --name kafka-example-service-adapter
  </pre>

1. Upload the example service adapter to the BOSH director:
  <pre class="terminal">
    $ bosh upload release
  </pre>

## <a id="set_up_odb"></a> Step 4: Set Up the On-Demand Service Broker

1. Download the [on-demand service broker from PivNet](https://network.pivotal.io/products/on-demand-services-sdk/)

1. Upload the `on-demand-service-broker` release (replace X.Y.Z with the ODB release version):
  <pre class="terminal">
    $ bosh upload release on-demand-service-broker-X.Y.Z.tgz
  </pre>

## <a id="create_bosh"></a> Step 5: Create a BOSH Deployment

1. Create a new directory in your workspace and a `cloud_config.yml` for the BOSH Lite Director. For example:

    ```yaml
    vm_types:
    - name: container
      cloud_properties: {}

    networks:
    - name: kafka
      type: manual
      subnets:
      - range: 10.244.1.0/24
        gateway: 10.244.1.1
        az: lite
        cloud_properties: {}

    disk_types:
    - name: ten
      disk_size: 10_000
      cloud_properties: {}

    azs:
    - name: lite
      cloud_properties: {}

    compilation:
      workers: 2
      reuse_compilation_vms: true
      network: kafka
      az: lite
      cloud_properties: {}
    ```

1. Update the BOSH Lite cloud config using the deployment manifest created in the previous step:
  <pre class="terminal">
    $ bosh update cloud-config cloud\_config.yml
  </pre>

1. Obtain the URL and UUID BOSH Lite director information:
  <pre class="terminal">
    $ bosh status
  </pre>
  This command produces output similar to the following:
  <pre class="terminal">
    â†’ bosh status
    Config
                 /Users/pivotal/.bosh_config

    Director
      Name       Bosh Lite Director
      URL        https<span>:</span>//192.168.50.4:25555
      Version    1.3215.0 (00000000)
      User       admin
      UUID       17a45148-1d00-43bc-af28-9882e5a6535a
      CPI        warden\_cpi
      dns        disabled
      compiled\_package\_cache enabled (provider: local)
      snapshots  disabled
  </pre>
  Record the URL and UUID from your output. You will add them to the `deployment_manifest.yml` in the next step.

1. Create a BOSH Lite deployment manifest in a file called `deployment_manifest.yml` using the following as a base.
<p class="note">Replace `BOSH_LITE_UUID`, `BOSH_LITE_URL` and `PCF_DEV_DOMAIN` with the values obtained in the previous steps.</p>

    ```yaml
    name: kafka-on-demand-broker

    director_uuid: BOSH-LITE-UUID

    releases:
    - name: &broker-release on-demand-service-broker
      version: latest
    - name: &service-adapter-release kafka-example-service-adapter
      version: latest
    - name: &service-release kafka-example-service
      version: latest

    stemcells:
    - alias: trusty
      os: ubuntu-trusty
      version: STEMCELL-VERSION

    instance_groups:
    - name: kafka-on-demand-broker
      instances: 1
      vm_type: container
      persistent_disk_type: ten
      stemcell: trusty
      azs: [lite]
      networks:
      - name: kafka
      jobs:
      - name: kafka-service-adapter
        release: *service-adapter-release
      - name: admin_tools
        release: *service-release
      - name: broker
        release: *broker-release
        properties:
          port: 8080
          username: broker #or replace with your own
          password: password #or replace with your own
          disable_ssl_cert_verification: true
          bosh:
            url: BOSH-LITE-URL
            authentication:
              basic:
                username: admin
                password: admin
          cf:
            url: https://api.PCF-DEV-DOMAIN
            authentication:
              url: https://uaa.PCF-DEV-DOMAIN
              user_credentials:
                username: admin
                password: admin
          service_adapter:
            path: /var/vcap/packages/odb-service-adapter/bin/service-adapter
          service_deployment:
            releases:
            - name: *service-release
              version: SERVICE-RELEASE-VERSION
              jobs: [kafka_server, zookeeper_server]
            stemcell:
              os: ubuntu-trusty
              version: STEMCELL-VERSION
          service_catalog:
            id: D94A086D-203D-4966-A6F1-60A9E2300F72
            service_name: kafka-service-with-odb
            service_description: Kafka Service
            bindable: true
            plan_updatable: true
            tags: [kafka]
            plans:
            - name: small
              plan_id: 11789210-D743-4C65-9D38-C80B29F4D9C8
              description: A Kafka deployment with a single instance of each job and persistent disk
              instance_groups:
              - name: kafka_server
                vm_type: container
                instances: 1
                persistent_disk_type: ten
                azs: [lite]
                networks: [kafka]
              - name: zookeeper_server
                vm_type: container
                instances: 1
                persistent_disk_type: ten
                azs: [lite]
                networks: [kafka]
              properties:
                auto_create_topics: true
                default_replication_factor: 1

    update:
      canaries: 1
      canary_watch_time: 30000-180000
      update_watch_time: 30000-180000
      max_in_flight: 4
    ```

1. Change the BOSH deployment to use the deployment manifest created in the previous step:
    <pre class="terminal">
    $ bosh deployment deployment\_manifest.yml
    </pre>

1. Deploy the manifest:
    <pre class="terminal">
    $ bosh deploy
    </pre>

1. Obtain the IP address of the deployed broker:
    <pre class="terminal">
    $ bosh instances
    </pre>

    This command produces output similar to the following:

    <pre class="terminal">
    Acting as client 'admin' on deployment 'kafka-on-demand-broker' on 'Bosh Lite Director'

    Director task 147

    Task 147 done

    +--------------------------------------------------+---------+-----+-----------+------------+
    | Instance                                         | State   | AZ  | VM Type   | IPs        |
    +--------------------------------------------------+---------+-----+-----------+------------+
    | broker/0 (59231277-d7b8-46bb-8bbb-8154b6bae347)* | running | n/a | container | 10.244.1.2 |
    +--------------------------------------------------+---------+-----+-----------+------------+

    (*) Bootstrap node

    Instances total: 1
    </pre>

    Record the IP address of the broker. You will use this in the next step to create a service broker.

## <a id="create_service"></a> Step 6: Create a Service Broker on PCF Dev

1. Create a service broker on PCF Dev and enable access to its service offering. You will need the broker's credentials set in the deployment manifest and the IP of the broker VM.
    <pre class="terminal">
    $ cf create-service-broker kafka-broker broker password http<span>:</span>//BROKER-IP:8080
    </pre>
    Where:<br>
    `BROKER-IP` is the value obtained in the previous step.<br>
    For more details on service brokers see [here](http://docs.cloudfoundry.org/services/api.html).

1. Enable access to the broker's service plans:
    <pre class="terminal">
    $ cf enable-service-access kafka-service-with-odb
    </pre>

1. View the services offered by the broker in the marketplace:
    <pre class="terminal">
    $ cf marketplace
    </pre>

    This command produces output similar to the following:

    <pre class="terminal">
    Getting services from marketplace in org pcfdev-org / space pcfdev-space as admin...
    OK

    service                  plans        description
    kafka-service-with-odb   small        Kafka Service
    p-mysql                  512mb, 1gb   MySQL databases on demand
    p-rabbitmq               standard     RabbitMQ is a robust and scalable high-performance multi-protocol messaging broker.
    p-redis                  shared-vm    Redis service to provide a key-value store
    </pre>

1. Create a service instance using the Kafka on-demand broker.

    <pre class="terminal">
    $ cf create-service kafka-service-with-odb small k1
    </pre>

## <a id="status"></a> Step 7: Verify Your BOSH Deployment and On-Demand Service

1. Check the status of your service:
    <pre class="terminal">
    $ cf service k1
    </pre>
    Initially, the service status state is: `create in progress`. After the service is created, the status changes to: `create succeeded`.

1. Verify that the on-demand service is provisioned in the BOSH deployment
    <pre class="terminal">
    $ bosh deployments
    </pre>

    The output of this command appears as follows:

    <pre class="terminal">
    +-------------------------------------------------------+---------------------------------------+--------------------------------------------------+--------------+
    | Name                                                  | Release(s)                            | Stemcell(s)                                      | Cloud Config |
    +-------------------------------------------------------+---------------------------------------+--------------------------------------------------+--------------+
    | kafka-on-demand-broker                                | kafka-example-service-adapter/0+dev.2 | bosh-warden-boshlite-ubuntu-trusty-go\_agent/<%= vars.odb_warden_stemcell_version %> | latest       |
    |                                                       | on-demand-service-broker/0.2.0+dev.1  |                                                  |              |
    +-------------------------------------------------------+---------------------------------------+--------------------------------------------------+--------------+
    | service-instance\_2715262c-8564-4cd9-b629-0ae99e6aa4b9 | kafka-example-service/0+dev.2         | bosh-warden-boshlite-ubuntu-trusty-go\_agent/<%= vars.odb_warden_stemcell_version %> | latest       |
    +-------------------------------------------------------+---------------------------------------+--------------------------------------------------+--------------+
    </pre>

    This example shows that the service instance is provisioned and the service releases are specified in the ODB deployment manifest.


## <a id="use"></a> Step 8: Use Your On-Demand Service

The [Kafka Example App](https://github.com/pivotal-cf-experimental/kafka-example-app) shows how you can use the service instance that you created with `cf create-service`.

1. Clone the [Kafka example app](https://github.com/pivotal-cf-experimental/kafka-example-app) in your workspace:
    <pre class="terminal">
    $ git clone https<span>:</span>//github.com/pivotal-cf-experimental/kafka-example-app.git
    </pre>

1. Push the app.
    <pre class="terminal">
    $ cd kafka-example-app
    $ cf push --no-start
    </pre>

1. Bind the app to your service instance:
    <pre class="terminal">
    $ cf bind-service kafka-example-app k1
    </pre>
    <p class="note"><strong>Note</strong>: You can use <code>cf bs</code> as an alias for <code>cf bind-service</code></p>

1. Start the app:
    <pre class="terminal">
    $ cf start kafka-example-app
    </pre>

Now the app runs at `https:/kafka-example-app.PCF-DEV-DOMAIN`, and you can use it to read and write to your on-demand Kafka service instance. For example:

* To write data, run `curl -XPOST http://kafka-example-app.PCF-DEV-DOMAIN/queues/my-queue -d SOME-DATA`
* To read data, run `curl http://kafka-example-app.PCF-DEV-DOMAIN/queues/my-queue`
